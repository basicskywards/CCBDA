{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import autoencoder\n",
    "import model\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = ['INTC', 'AMD', 'CSCO', 'AAPL', 'MU', 'NVDA', 'QCOM', 'AMZN', 'NFLX', 'FB', 'GOOG', 'BABA', 'EBAY', 'IBM', 'XLNX', 'TXN', 'NOK', 'TSLA', 'MSFT', 'SNPS']\n",
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_data = {}\n",
    "for ticker in companies:\n",
    "    tmp = pdr.get_data_yahoo(symbols=ticker, start=datetime(2018, 2, 1), end=datetime(2019, 5, 9))\n",
    "    comp_data[ticker] = tmp\n",
    "    #print(len(tmp))\n",
    "\n",
    "oil = pdr.get_data_yahoo(symbols='OIL', start=datetime(2018, 2, 1), end=datetime(2019, 5, 9))\n",
    "len(oil)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, learning_rate, num_layers, size, size_layer, output_size, forget_bias = 0.1):\n",
    "        \n",
    "        def lstm_cell(size_layer):\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
    "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell([lstm_cell(size_layer) for _ in range(num_layers)], state_is_tuple = False)\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(rnn_cells, output_keep_prob = forget_bias)\n",
    "        self.hidden_layer = tf.placeholder(tf.float32, (None, num_layers * 2 * size_layer))\n",
    "        self.outputs, self.last_state = tf.nn.dynamic_rnn(drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32)\n",
    "        rnn_W = tf.Variable(tf.random_normal((size_layer, output_size)))\n",
    "        rnn_B = tf.Variable(tf.random_normal([output_size]))\n",
    "        self.logits = tf.matmul(self.outputs[-1], rnn_W) + rnn_B\n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_layers = 1\n",
    "size_layer = 128\n",
    "timestamp = 1\n",
    "epoch = 500\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ARIMA model using stats model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import statsmodels.api as sm\n",
    "from itertools import product\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def reverse_close(array):\n",
    "    return minmax.inverse_transform(array.reshape((-1,1))).reshape((-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rise: CP\n",
    "ùë°ùëúùëëùëéùë¶ > CPùë¶ùëíùë†ùë°ùëíùëüùëëùëéùë¶ , ùëÖùëê‚Ñéùëéùëõùëîùëí > 2%\n",
    "‚ó¶ Remain Stable: ùëÖ\n",
    "ùëê‚Ñéùëéùëõùëîùëí ‚â§ 2%\n",
    "‚ó¶ Fall: CP\n",
    "ùë°ùëúùëëùëéùë¶ < CPùë¶ùëíùë†ùë°ùëíùëüùëëùëéùë¶ , ùëÖùëê‚Ñéùëéùëõùëîùëí > 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_stock(pred_close_price, today_close_price):\n",
    "    \n",
    "    percent_change = abs(pred_close_price - today_close_price) * 100/ today_close_price\n",
    "    \n",
    "    if percent_change > 2.0:\n",
    "        if (pred_close_price > today_close_price):\n",
    "            return 0 # rise\n",
    "        elif (pred_close_price <= today_close_price):\n",
    "            return 2 # fall\n",
    "    elif percent_change < 2.0:\n",
    "        return 1 # stable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intl = comp_data['INTC']\n",
    "intl['oil_high'] = oil['High']\n",
    "intl['oil_low'] = oil['Low']\n",
    "intl['oil_open'] = oil['Open']\n",
    "intl['oil_close'] = oil['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "final_res = []\n",
    "for cpn in companies:\n",
    "    \n",
    "    intl = comp_data[cpn]\n",
    "    intl['oil_high'] = oil['High']\n",
    "    intl['oil_low'] = oil['Low']\n",
    "    intl['oil_open'] = oil['Open']\n",
    "    intl['oil_close'] = oil['Close']\n",
    "    \n",
    "    y_train = intl.Close[1:]\n",
    "    x_train = intl.iloc[:-1,:]\n",
    "    x_test = intl.iloc[-1, :]\n",
    "    \n",
    "    df_x_test = MinMaxScaler().fit_transform(x_test.astype('float32'))\n",
    "    df_x_test = pd.DataFrame(df_x_test)\n",
    "    thought_vector_x_test = autoencoder.reducedimension(df_x_test.values, 3, 0.001, 128, 100)\n",
    "    \n",
    "    minmax = MinMaxScaler().fit(y_train.values.reshape((-1,1)))\n",
    "    df_log = MinMaxScaler().fit_transform(x_train.astype('float32'))\n",
    "    df_log = pd.DataFrame(df_log)\n",
    "    \n",
    "    #minmax = MinMaxScaler().fit(intl.iloc[:, 3].values.reshape((-1,1)))\n",
    "    \n",
    "    ##df_log = MinMaxScaler().fit_transform(intl.iloc[:, 1:].astype('float32'))\n",
    "    \n",
    "    #df_log = MinMaxScaler().fit_transform(intl.astype('float32'))\n",
    "\n",
    "    #df_log = pd.DataFrame(df_log)\n",
    "\n",
    "    thought_vector = autoencoder.reducedimension(df_log.values, 3, 0.001, 128, 100)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    modelnn = Model(0.01, num_layers, thought_vector.shape[1], size_layer, 1, dropout_rate)\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "        total_loss = 0\n",
    "        for k in range(0, (thought_vector.shape[0] // timestamp) * timestamp, timestamp):\n",
    "            \n",
    "            batch_x = np.expand_dims(thought_vector[k: k + timestamp, :], axis = 0)\n",
    "            \n",
    "            #batch_y = df_log.values[k + 1: k + timestamp + 1, 3].reshape([-1, 1])\n",
    "            batch_y = y_train.values[k : k + timestamp].reshape([-1, 1])\n",
    "\n",
    "            last_state, _, loss = sess.run([modelnn.last_state, \n",
    "                                            modelnn.optimizer, \n",
    "                                            modelnn.cost], feed_dict={modelnn.X: batch_x, \n",
    "                                                                      modelnn.Y: batch_y, \n",
    "                                                                      modelnn.hidden_layer: init_value})\n",
    "            init_value = last_state\n",
    "            total_loss += loss\n",
    "        total_loss /= (thought_vector.shape[0] // timestamp)\n",
    "        #if (i + 1) % 100 == 0:\n",
    "         #   print('epoch:', i + 1, 'avg loss:', total_loss)\n",
    "\n",
    "    #output_predict = np.zeros(((thought_vector.shape[0] // timestamp) * timestamp, 1))\n",
    "    output_predict = np.zeros(((thought_vector_x_test.shape[0] // timestamp) * timestamp, 1))\n",
    "\n",
    "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
    "    tmp1 = (thought_vector.shape[0] // timestamp) * timestamp\n",
    "    #tmp2 = len(df_log)\n",
    "    \n",
    "    tmp2 = len(df_x_test)\n",
    "    tmp3_go = tmp2 - tmp1\n",
    "    \n",
    "    for k in range(0, (thought_vector.shape[0] // timestamp) * timestamp, timestamp):\n",
    "        out_logits, last_state = sess.run([modelnn.logits, modelnn.last_state], \n",
    "            feed_dict = {modelnn.X:np.expand_dims(thought_vector_x_test[k + tmp3_go: k + tmp3_go + timestamp, :], axis = 0),\n",
    "                                         modelnn.hidden_layer: init_value})\n",
    "        init_value = last_state\n",
    "        output_predict[k: k + timestamp, :] = out_logits\n",
    "        \n",
    "    #sess.close()\n",
    "    \n",
    "    Qs = range(0, 1)\n",
    "    qs = range(0, 2)\n",
    "    Ps = range(0, 2)\n",
    "    ps = range(0, 2)\n",
    "    D=1\n",
    "    parameters = product(ps, qs, Ps, Qs)\n",
    "    parameters_list = list(parameters)\n",
    "    best_aic = float(\"inf\")\n",
    "    for param in parameters_list:\n",
    "        try:\n",
    "            #arima=sm.tsa.statespace.SARIMAX(df_log.iloc[:,3].values, order=(param[0], D, param[1]), seasonal_order=(param[2], D, param[3], 1)).fit(disp=-1)\n",
    "            arima=sm.tsa.statespace.SARIMAX(y_train.values, order=(param[0], D, param[1]), seasonal_order=(param[2], D, param[3], 1)).fit(disp=-1)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "        aic = arima.aic\n",
    "        if aic < best_aic and aic:\n",
    "            best_arima = arima\n",
    "            best_aic = aic\n",
    "\n",
    "    #best_aic\n",
    "\n",
    "\n",
    "    pred_arima = best_arima.predict()\n",
    "\n",
    "\n",
    "\n",
    "    boundary = (thought_vector.shape[0] // timestamp) * timestamp\n",
    "    start = thought_vector.shape[0] - boundary\n",
    "    #stack_predict = np.vstack([pred_arima[:boundary], output_predict.reshape((-1))]).T\n",
    "    stack_predict = np.vstack([pred_arima[-1], output_predict.reshape((-1))]).T\n",
    "\n",
    "    #where_below_0 = np.where(stack_predict < 0)\n",
    "    #where_higher_1 = np.where(stack_predict > 1)\n",
    "    #stack_predict[where_below_0[0], where_below_0[1]] = 0\n",
    "    #stack_predict[where_higher_1[0], where_higher_1[1]] = 1\n",
    "\n",
    "    params_xgd = {\n",
    "        'max_depth': 7,\n",
    "        'objective': 'reg:logistic',\n",
    "        'learning_rate': 0.05,\n",
    "        'n_estimators': 10000\n",
    "        }\n",
    "    \n",
    "    train_Y = df_log.values[start:, 3]\n",
    "\n",
    "    clf = xgb.XGBRegressor(**params_xgd) ## **?\n",
    "\n",
    "    clf.fit(stack_predict,train_Y, eval_set=[(stack_predict,train_Y)], \n",
    "            eval_metric='rmse', early_stopping_rounds=20, verbose=False)\n",
    "    \n",
    "    stacked = clf.predict(stack_predict)\n",
    "\n",
    "    true_close = reverse_close(train_Y)\n",
    "    pred_close = reverse_close(stacked) # \n",
    "    #pred_ = pred_arima[-1]\n",
    "    \n",
    "    pred_ = pred_close[-1] # t + 1 price\n",
    "    #pred_ = pred_close\n",
    "    today_ = true_close[-1] # t price\n",
    "    wow_pred = pred_stock(pred_, today_)\n",
    "    final_res.append(wow_pred)\n",
    "    print('====> {}: {} ----> today: {} --- pred_tomorrow: {}'.format(cpn, wow_pred, today_, pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> INTC: 1 ----> today: 46.619998931884766 --- pred_tomorrow: [46.838593]\n",
      "====> AMD: 1 ----> today: 27.209999084472656 --- pred_tomorrow: [26.95659]\n",
      "====> CSCO: 1 ----> today: 52.91999816894531 --- pred_tomorrow: [53.004677]\n",
      "====> AAPL: 1 ----> today: 200.72000122070312 --- pred_tomorrow: [202.88957]\n",
      "====> MU: 1 ----> today: 39.27000045776367 --- pred_tomorrow: [38.75364]\n",
      "====> NVDA: 2 ----> today: 170.19000244140625 --- pred_tomorrow: [165.81253]\n",
      "====> QCOM: 1 ----> today: 83.77999877929688 --- pred_tomorrow: [84.59456]\n",
      "====> AMZN: 1 ----> today: 1899.8699951171875 --- pred_tomorrow: [1905.7084]\n",
      "====> NFLX: 1 ----> today: 362.75 --- pred_tomorrow: [360.71155]\n",
      "====> FB: 1 ----> today: 188.64999389648438 --- pred_tomorrow: [188.98941]\n",
      "====> GOOG: 1 ----> today: 1162.3800048828125 --- pred_tomorrow: [1163.8878]\n",
      "====> BABA: 1 ----> today: 179.0399932861328 --- pred_tomorrow: [178.98433]\n",
      "====> EBAY: 1 ----> today: 37.619998931884766 --- pred_tomorrow: [37.550915]\n",
      "====> IBM: 1 ----> today: 135.33999633789062 --- pred_tomorrow: [136.50063]\n",
      "====> XLNX: 1 ----> today: 116.69999694824219 --- pred_tomorrow: [117.52056]\n",
      "====> TXN: 1 ----> today: 112.1500015258789 --- pred_tomorrow: [111.88438]\n",
      "====> NOK: 1 ----> today: 4.949999809265137 --- pred_tomorrow: [5.0337443]\n",
      "====> TSLA: 1 ----> today: 241.97999572753906 --- pred_tomorrow: [245.69684]\n",
      "====> MSFT: 1 ----> today: 125.5 --- pred_tomorrow: [125.05342]\n",
      "====> SNPS: 1 ----> today: 118.9000015258789 --- pred_tomorrow: [117.75561]\n"
     ]
    }
   ],
   "source": [
    "final_res = []\n",
    "for cpn in companies:\n",
    "    \n",
    "    intl = comp_data[cpn]\n",
    "    intl['oil_high'] = oil['High']\n",
    "    intl['oil_low'] = oil['Low']\n",
    "    intl['oil_open'] = oil['Open']\n",
    "    intl['oil_close'] = oil['Close']\n",
    "    \n",
    "    y_train = intl.Close[1:]\n",
    "    x_train = intl.iloc[:-1,:]\n",
    "    #print(\"COMPANY\\n\", intl.tail())\n",
    "    #print(\"y-TRAI\\n\", y_train.tail())\n",
    "    #print(\"X-TRAIN\\n\", x_train.tail())\n",
    "    y_train = y_train.values\n",
    "    x_train = x_train.values\n",
    "    \n",
    "    x_test = intl.iloc[-1, :]\n",
    "    #print(\"X-test\\n\", x_test)\n",
    "    x_test = x_test.values.reshape(1, -1)\n",
    "    #print(x_test)\n",
    "    #df_x_test = MinMaxScaler().fit_transform(x_test.astype('float32'))\n",
    "    #df_x_test = pd.DataFrame(df_x_test)\n",
    "    \n",
    "    #x_train = autoencoder.reducedimension(x_train, 5, 0.001, 128, 100)\n",
    "    #x_test = autoencoder.reducedimension(x_test, 5, 0.001, 128, 100)\n",
    "    \n",
    "    #minmax = MinMaxScaler().fit(y_train.values.reshape((-1,1))) # y train\n",
    "    \n",
    "    #minmax = pd.DataFrame(minmax)\n",
    "    #minmax = np.array(minmax)\n",
    "    #minmax = pd.DataFrame(minmax.reshape((-1, 1)))\n",
    "    \n",
    "    #df_log = MinMaxScaler().fit_transform(x_train.astype('float32'))\n",
    "    #df_log = pd.DataFrame(df_log) # x train\n",
    "    \n",
    "    #df_log = df_log.values\n",
    "    \n",
    "    #print('y_train minmax: {}'.format(len(minmax)))\n",
    "    #print('df_log: {}'.format(len(df_log)))\n",
    "\n",
    "    \n",
    "    \n",
    "    # xgbOost \n",
    "    params_xgd = {\n",
    "        'max_depth': 7,\n",
    "        'objective': 'reg:logistic',\n",
    "        'learning_rate': 0.05,\n",
    "        'n_estimators': 10000\n",
    "        }\n",
    "    \n",
    "    #train_Y = df_log.values[start:, 3]\n",
    "\n",
    "    #clf = xgb.XGBRegressor() ## **?\n",
    "    \n",
    "    #clf.fit(stack_predict,y_train)\n",
    "    clf = xgb.XGBRegressor()\n",
    "    #model = xgb.XGBRegressor()\n",
    "    #model.fit(df_log,minmax)\n",
    "    #print (model)\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    stacked = clf.predict(x_test)\n",
    "\n",
    "    #true_close = reverse_close(train_Y)\n",
    "    #pred_close = reverse_close(stacked) # \n",
    "    \n",
    "    #pred_ = pred_arima[-1]\n",
    "    \n",
    "    #pred_ = pred_close[-1] # t + 1 price\n",
    "    \n",
    "    pred_ = stacked\n",
    "    today_ = y_train[-1] # t price\n",
    "    \n",
    "    wow_pred = pred_stock(pred_, today_)\n",
    "    final_res.append(wow_pred)\n",
    "    print('====> {}: {} ----> today: {} --- pred_tomorrow: {}'.format(cpn, wow_pred, today_, pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoder not work\n",
    "short term data not good\n",
    "rnn not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download up-to-date stock prices for validate predcition above ( run after 9pm TW time)\n",
    "comp_data_check_pred = {}\n",
    "for ticker in companies:\n",
    "    tmp = pdr.get_data_yahoo(symbols=ticker, start=datetime(2019, 5, 1), end=datetime(2019, 5, 10))\n",
    "    comp_data_check_pred[ticker] = tmp\n",
    "    #print(len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 High        Low       Open      Close      Volume  Adj Close\n",
      "Date                                                                         \n",
      "2019-05-06  51.279999  50.189999  50.250000  51.220001  26245200.0  51.220001\n",
      "2019-05-07  50.880001  49.930000  50.599998  50.480000  29713400.0  50.480000\n",
      "2019-05-08  50.790001  49.070000  50.200001  49.240002  36812400.0  49.240002\n",
      "2019-05-09  48.290001  46.049999  47.900002  46.619999  59642200.0  46.619999\n",
      "2019-05-10  46.799999  45.099998  46.439999  46.200001  42385800.0  46.200001\n",
      "\n",
      "INTC: 1\n",
      "                 High        Low       Open      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2019-05-06  27.500000  26.450001  26.719999  27.420000  70344100  27.420000\n",
      "2019-05-07  27.350000  26.209999  27.200001  26.660000  75868800  26.660000\n",
      "2019-05-08  27.709999  26.270000  26.410000  27.090000  65967500  27.090000\n",
      "2019-05-09  27.379999  26.030001  26.700001  27.209999  73150900  27.209999\n",
      "2019-05-10  28.100000  26.930000  27.030001  27.959999  82859300  27.959999\n",
      "\n",
      "AMD: 0\n",
      "                 High        Low       Open      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2019-05-06  54.759998  53.560001  53.860001  54.590000  17025900  54.590000\n",
      "2019-05-07  54.240002  52.939999  53.860001  53.450001  25289700  53.450001\n",
      "2019-05-08  53.939999  53.130001  53.169998  53.470001  21525100  53.470001\n",
      "2019-05-09  53.209999  52.230000  52.820000  52.919998  24322800  52.919998\n",
      "2019-05-10  53.549999  51.950001  52.610001  53.360001  21318000  53.360001\n",
      "\n",
      "CSCO: 1\n",
      "                  High         Low        Open       Close      Volume  \\\n",
      "Date                                                                     \n",
      "2019-05-06  208.839996  203.500000  204.289993  208.479996  32443100.0   \n",
      "2019-05-07  207.419998  200.830002  205.880005  202.860001  38763700.0   \n",
      "2019-05-08  205.339996  201.750000  201.899994  202.899994  26339500.0   \n",
      "2019-05-09  201.679993  196.660004  200.399994  200.720001  34908600.0   \n",
      "2019-05-10  198.850006  192.770004  197.419998  197.179993  41183400.0   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  207.680222  \n",
      "2019-05-07  202.081787  \n",
      "2019-05-08  202.121628  \n",
      "2019-05-09  199.949997  \n",
      "2019-05-10  197.179993  \n",
      "\n",
      "AAPL: 1\n",
      "                 High        Low       Open      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2019-05-06  42.290001  41.000000  41.400002  42.130001  25776000  42.130001\n",
      "2019-05-07  41.930000  39.730000  41.680000  40.259998  35094100  40.259998\n",
      "2019-05-08  40.490002  39.580002  39.860001  39.750000  26190100  39.750000\n",
      "2019-05-09  39.630001  38.200001  39.099998  39.270000  27844400  39.270000\n",
      "2019-05-10  39.290001  37.650002  39.009998  38.939999  30350900  38.939999\n",
      "\n",
      "MU: 1\n",
      "                  High         Low        Open       Close    Volume  \\\n",
      "Date                                                                   \n",
      "2019-05-06  180.339996  174.000000  175.500000  179.850006  10554400   \n",
      "2019-05-07  177.899994  171.169998  177.899994  173.110001  13880500   \n",
      "2019-05-08  177.149994  171.520004  172.000000  173.919998  10479200   \n",
      "2019-05-09  171.529999  165.399994  171.139999  170.190002  16506200   \n",
      "2019-05-10  171.589996  164.000000  168.949997  168.820007  14220700   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  179.850006  \n",
      "2019-05-07  173.110001  \n",
      "2019-05-08  173.919998  \n",
      "2019-05-09  170.190002  \n",
      "2019-05-10  168.820007  \n",
      "\n",
      "NVDA: 1\n",
      "                 High        Low       Open      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2019-05-06  88.699997  86.139999  86.330002  88.250000  15682100  88.250000\n",
      "2019-05-07  88.150002  84.779999  87.199997  85.199997  21579500  85.199997\n",
      "2019-05-08  85.720001  84.110001  84.849998  84.540001  15500700  84.540001\n",
      "2019-05-09  84.839996  82.260002  83.370003  83.779999  14516000  83.779999\n",
      "2019-05-10  86.330002  83.349998  83.379997  85.839996  15951100  85.839996\n",
      "\n",
      "QCOM: 0\n",
      "                   High          Low         Open        Close   Volume  \\\n",
      "Date                                                                      \n",
      "2019-05-06  1959.000000  1910.500000  1917.979980  1950.550049  5417800   \n",
      "2019-05-07  1949.099976  1903.380005  1939.989990  1921.000000  5902100   \n",
      "2019-05-08  1935.369995  1910.000000  1918.869995  1917.770020  4078600   \n",
      "2019-05-09  1909.400024  1876.000000  1900.000000  1899.869995  5308300   \n",
      "2019-05-10  1903.790039  1856.000000  1898.000000  1889.979980  5712700   \n",
      "\n",
      "              Adj Close  \n",
      "Date                     \n",
      "2019-05-06  1950.550049  \n",
      "2019-05-07  1921.000000  \n",
      "2019-05-08  1917.770020  \n",
      "2019-05-09  1899.869995  \n",
      "2019-05-10  1889.979980  \n",
      "\n",
      "AMZN: 1\n",
      "                  High         Low        Open       Close   Volume  \\\n",
      "Date                                                                  \n",
      "2019-05-06  381.350006  376.000000  377.690002  378.670013  5793100   \n",
      "2019-05-07  379.910004  365.809998  377.000000  370.459991  6974900   \n",
      "2019-05-08  369.000000  361.359985  367.920013  364.369995  6572000   \n",
      "2019-05-09  364.200012  352.750000  360.899994  362.750000  5882600   \n",
      "2019-05-10  365.260010  353.059998  361.619995  361.040009  5652800   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  378.670013  \n",
      "2019-05-07  370.459991  \n",
      "2019-05-08  364.369995  \n",
      "2019-05-09  362.750000  \n",
      "2019-05-10  361.040009  \n",
      "\n",
      "NFLX: 1\n",
      "                  High         Low        Open       Close    Volume  \\\n",
      "Date                                                                   \n",
      "2019-05-06  194.279999  190.550003  191.240005  193.880005  13994900   \n",
      "2019-05-07  192.899994  187.850006  192.539993  189.770004  16253000   \n",
      "2019-05-08  190.720001  188.550003  189.389999  189.539993  12505700   \n",
      "2019-05-09  189.770004  186.259995  187.199997  188.649994  12967000   \n",
      "2019-05-10  190.000000  184.589996  188.250000  188.339996  12568700   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  193.880005  \n",
      "2019-05-07  189.770004  \n",
      "2019-05-08  189.539993  \n",
      "2019-05-09  188.649994  \n",
      "2019-05-10  188.339996  \n",
      "\n",
      "FB: 1\n",
      "                   High          Low         Open        Close   Volume  \\\n",
      "Date                                                                      \n",
      "2019-05-06  1190.849976  1166.260010  1166.260010  1189.390015  1563900   \n",
      "2019-05-07  1190.439941  1161.040039  1180.469971  1174.099976  1551400   \n",
      "2019-05-08  1180.423950  1165.739990  1172.010010  1166.270020  1309300   \n",
      "2019-05-09  1169.660034  1150.849976  1159.030029  1162.380005  1185700   \n",
      "2019-05-10  1172.599976  1142.500000  1163.589966  1164.270020  1314500   \n",
      "\n",
      "              Adj Close  \n",
      "Date                     \n",
      "2019-05-06  1189.390015  \n",
      "2019-05-07  1174.099976  \n",
      "2019-05-08  1166.270020  \n",
      "2019-05-09  1162.380005  \n",
      "2019-05-10  1164.270020  \n",
      "\n",
      "GOOG: 1\n",
      "                  High         Low        Open       Close    Volume  \\\n",
      "Date                                                                   \n",
      "2019-05-06  189.000000  184.830002  185.169998  188.240005  23941200   \n",
      "2019-05-07  186.449997  179.630005  186.050003  181.429993  22663200   \n",
      "2019-05-08  183.199997  178.580002  180.949997  179.589996  16611100   \n",
      "2019-05-09  180.695007  173.070007  175.429993  179.039993  22727800   \n",
      "2019-05-10  180.789993  174.100006  180.179993  178.000000  18960800   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  188.240005  \n",
      "2019-05-07  181.429993  \n",
      "2019-05-08  179.589996  \n",
      "2019-05-09  179.039993  \n",
      "2019-05-10  178.000000  \n",
      "\n",
      "BABA: 1\n",
      "                 High        Low       Open      Close   Volume  Adj Close\n",
      "Date                                                                      \n",
      "2019-05-06  38.060001  37.590000  37.639999  37.880001  6504700  37.880001\n",
      "2019-05-07  37.849998  37.360001  37.610001  37.680000  7808500  37.680000\n",
      "2019-05-08  37.740002  37.290001  37.680000  37.540001  5943700  37.540001\n",
      "2019-05-09  37.849998  36.959999  37.250000  37.619999  6454700  37.619999\n",
      "2019-05-10  37.580002  36.709999  37.480000  37.380001  8860100  37.380001\n",
      "\n",
      "EBAY: 1\n",
      "                  High         Low        Open       Close     Volume  \\\n",
      "Date                                                                    \n",
      "2019-05-06  140.690002  137.899994  138.300003  140.380005  2793300.0   \n",
      "2019-05-07  139.509995  136.190002  139.149994  137.639999  4726800.0   \n",
      "2019-05-08  138.699997  137.130005  137.770004  138.000000  3818900.0   \n",
      "2019-05-09  135.580002  133.029999  134.889999  135.339996  4192700.0   \n",
      "2019-05-10  135.750000  132.419998  134.880005  135.320007  3977600.0   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  138.732071  \n",
      "2019-05-07  136.024231  \n",
      "2019-05-08  136.380005  \n",
      "2019-05-09  135.339996  \n",
      "2019-05-10  135.320007  \n",
      "\n",
      "IBM: 1\n",
      "                  High         Low        Open       Close   Volume  \\\n",
      "Date                                                                  \n",
      "2019-05-06  118.870003  113.690002  115.000000  118.809998  3316800   \n",
      "2019-05-07  119.400002  116.470001  117.900002  117.809998  5390000   \n",
      "2019-05-08  119.309998  116.709999  117.809998  117.690002  3223200   \n",
      "2019-05-09  117.750000  114.599998  115.980003  116.699997  3565400   \n",
      "2019-05-10  119.120003  115.129997  116.440002  116.919998  3769300   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  118.809998  \n",
      "2019-05-07  117.809998  \n",
      "2019-05-08  117.690002  \n",
      "2019-05-09  116.699997  \n",
      "2019-05-10  116.919998  \n",
      "\n",
      "XLNX: 1\n",
      "                  High         Low        Open       Close     Volume  \\\n",
      "Date                                                                    \n",
      "2019-05-06  116.000000  113.500000  114.120003  115.860001  3974300.0   \n",
      "2019-05-07  114.430000  112.250000  114.000000  113.930000  5928100.0   \n",
      "2019-05-08  114.750000  112.480003  112.820000  112.559998  4819300.0   \n",
      "2019-05-09  112.839996  110.199997  110.879997  112.150002  4817500.0   \n",
      "2019-05-10  113.129997  109.360001  111.860001  112.599998  4171900.0   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  115.860001  \n",
      "2019-05-07  113.930000  \n",
      "2019-05-08  112.559998  \n",
      "2019-05-09  112.150002  \n",
      "2019-05-10  112.599998  \n",
      "\n",
      "TXN: 1\n",
      "            High   Low  Open  Close    Volume  Adj Close\n",
      "Date                                                    \n",
      "2019-05-06  5.16  5.05  5.06   5.14  28199200       5.14\n",
      "2019-05-07  5.10  4.98  5.07   5.04  39943400       5.04\n",
      "2019-05-08  5.04  4.98  4.99   4.98  22076200       4.98\n",
      "2019-05-09  4.97  4.90  4.92   4.95  29449800       4.95\n",
      "2019-05-10  4.96  4.86  4.91   4.93  22771600       4.93\n",
      "\n",
      "NOK: 1\n",
      "                  High         Low        Open       Close    Volume  \\\n",
      "Date                                                                   \n",
      "2019-05-06  258.350006  248.500000  250.020004  255.339996  10833900   \n",
      "2019-05-07  257.209991  245.100006  256.799988  247.059998  10131400   \n",
      "2019-05-08  250.600006  244.199997  246.940002  244.839996   6176400   \n",
      "2019-05-09  243.679993  236.940002  242.000000  241.979996   6711400   \n",
      "2019-05-10  241.990005  236.020004  239.750000  239.520004   6999000   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  255.339996  \n",
      "2019-05-07  247.059998  \n",
      "2019-05-08  244.839996  \n",
      "2019-05-09  241.979996  \n",
      "2019-05-10  239.520004  \n",
      "\n",
      "TSLA: 1\n",
      "                  High         Low        Open       Close    Volume  \\\n",
      "Date                                                                   \n",
      "2019-05-06  128.559998  126.110001  126.389999  128.149994  24239800   \n",
      "2019-05-07  127.180000  124.220001  126.459999  125.519997  36017700   \n",
      "2019-05-08  126.370003  124.750000  125.440002  125.510002  28419000   \n",
      "2019-05-09  125.790001  123.570000  124.290001  125.500000  27235800   \n",
      "2019-05-10  127.930000  123.820000  124.910004  127.129997  30905300   \n",
      "\n",
      "             Adj Close  \n",
      "Date                    \n",
      "2019-05-06  128.149994  \n",
      "2019-05-07  125.519997  \n",
      "2019-05-08  125.510002  \n",
      "2019-05-09  125.500000  \n",
      "2019-05-10  127.129997  \n",
      "\n",
      "MSFT: 1\n",
      "                  High         Low        Open       Close  Volume   Adj Close\n",
      "Date                                                                          \n",
      "2019-05-06  121.830002  118.370003  119.180000  121.529999  744600  121.529999\n",
      "2019-05-07  120.889999  118.589996  120.269997  119.570000  928700  119.570000\n",
      "2019-05-08  120.150002  118.300003  119.320000  119.360001  646300  119.360001\n",
      "2019-05-09  119.250000  116.889999  117.730003  118.900002  729700  118.900002\n",
      "2019-05-10  120.260002  116.610001  118.180000  119.820000  638500  119.820000\n",
      "\n",
      "SNPS: 1\n"
     ]
    }
   ],
   "source": [
    "# validate results of prediction everday\n",
    "val_res = []\n",
    "for cpn in comp_data_check_pred:\n",
    "    intl = comp_data_check_pred[cpn]\n",
    "    print(intl.tail())\n",
    "    tmr = intl.iloc[-1, 3]\n",
    "    yes = intl.iloc[-2, 3]\n",
    "    pred_ = pred_stock(tmr, yes)\n",
    "    val_res.append(pred_)\n",
    "    #print('yes: {}'.format(yes))\n",
    "    #print('tmr: {}'.format(tmr))\n",
    "    print('\\n{}: {}'.format(cpn, pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1] # GT 5/6 7/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1] # GT 5/7 7/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] # GT 5/8 17/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] # GT 5/9 18/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] #GT 5/19 17/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '0510_0760816'\n",
    "\n",
    "with open(file_name, 'r') as f:\n",
    "    x = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "pred_tmr = [int(tm) for tm in x]\n",
    "print(pred_tmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_correct_prediction: 17\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for i in range(len(val_res)):\n",
    "    val = val_res[i]\n",
    "    pre = pred_tmr[i]\n",
    "    if val == pre:\n",
    "        n_correct += 1\n",
    "print('n_correct_prediction: {}'.format(n_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '0510_0760816'\n",
    "def output_txt(file_name, list_pred):\n",
    "    \n",
    "    with open(file_name, \"w\") as f:\n",
    "        \n",
    "        for pred in list_pred:\n",
    "\n",
    "            f.write(\"%s\\n\"%(str(int(pred))))\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_txt(file_name, final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
